# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ScQ8cVOOlxVhB3U_wptVst1pwwL2u_IR
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPRegressor
from xgboost import XGBRegressor

def generate_data(num_rows):
    # Generate synthetic data
    data = {
        'Age': np.random.randint(18, 90, size=num_rows),
        'Gender': np.random.choice(['Male', 'Female'], size=num_rows),
        'Weight': np.random.uniform(40, 120, size=num_rows),
        'Height': np.random.uniform(140, 200, size=num_rows),
        'Smoker': np.random.choice(['Yes', 'No'], size=num_rows),
        'LOS': np.random.randint(1, 30, size=num_rows)  # Length of Stay
    }

    # Create a DataFrame
    df = pd.DataFrame(data)

    # Save the DataFrame to a CSV file
    df.to_csv('patient_data_large.csv', index=False)


def preprocess_data(data):
    # Convert categorical variables to numerical using one-hot encoding
    data = pd.get_dummies(data, columns=['Gender', 'Smoker'])

    # Preprocess data
    X = data.drop(columns=['LOS'])
    y = data['LOS']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    return X_train_scaled, X_test_scaled, y_train, y_test


def train_models(X_train, y_train):
    # Train neural network model
    nn_model = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500)
    xgb_model = XGBRegressor()

    nn_model.fit(X_train, y_train)
    xgb_model.fit(X_train, y_train)

    return nn_model, xgb_model

def evaluate_models(models, X_test, y_test):
    nn_model, xgb_model = models
    # Evaluate models
    nn_accuracy = nn_model.score(X_test, y_test)
    xgb_accuracy = xgb_model.score(X_test, y_test)

    return nn_accuracy, xgb_accuracy
def provide_insights(model, feature_names, X_test):
    # Provide actionable insights
    # For example, you could analyze feature importance or provide predictions for specific patients

    # Here, let's print feature importance for XGBoost model
    print("\nXGBoost Model Feature Importance:")
    for feature, importance in zip(feature_names, model.feature_importances_):
        print(f"{feature}: {importance}")

    # Analyze specific patient data
    sample_patient_data = X_test[0]  # Example: Taking the first test data point
    nn_prediction = model.predict([sample_patient_data])[0]

    print("\nSample Patient Data:")
    print(sample_patient_data)
    print("\nPredicted Length of Stay (Neural Network):", nn_prediction)

def main():
    # Generate data
    num_rows = 10000
    generate_data(num_rows)

    # Load data
    data = pd.read_csv("patient_data_large.csv")

    # Preprocess data
    X_train, X_test, y_train, y_test = preprocess_data(data)

    # Define feature names
    feature_names = ['Age', 'Gender', 'Weight', 'Height', 'Smoker_Yes', 'Smoker_No']

    # Train models
    models = train_models(X_train, y_train)

    # Evaluate models
    nn_accuracy, xgb_accuracy = evaluate_models(models, X_test, y_test)

    # Output results
    print("Neural Network Model Accuracy:", nn_accuracy)
    print("XGBoost Model Accuracy:", xgb_accuracy)

    # Provide actionable insights
    provide_insights(models[1], feature_names, X_test)  # Providing insights for XGBoost model

if __name__ == "__main__":
    main()